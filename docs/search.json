[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Saudações, seja muito bem-vindo (a)!",
    "section": "",
    "text": "Opa! Muito prazer, meu nome é Lucas Romão Gava, e fico feliz de ter você aqui e poder compartilhar um pouco do que aprendi na disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia. Este site é destinado ao meu caderno de aulas da disciplina, por favor, sinta-se à vontade para aprender um pouco sobre análise de dados utilizando o software R!\n\n\n\n\n\n\n\n\n\nSobre mim\nTécnico em Agropecuária pela Escola Família Agrícola de Castelo (EFA Castelo) em 2015, Engenheiro Agrônomo pela Universidade Federal do Espírito Santo (UFES) em 2023. Foi integrante do Laboratório de Biotecnologia Agrícola e Ambiental (BIOTA), lotado no Núcleo de Desenvolvimento Científico e Tecnológico em Manejo Fitossanitário de Pragas e Doenças (NUDEMAFI- UFES), trabalhando com controle biológico de doenças de plantas e com microrganismos capazes de mitigar estresses abióticos. Atualmente é mestrando no Programa de Pós-graduação em Fitopatologia da Universidade Federal de Viçosa (UFV) e integrante do Laboratório de Manejo Integrado de Doenças de Plantas (LAMID) com foco em análise de dados.\n\n\n\n\n\n\n\n\n\nSobre este site\nA proposta desse website é disponibilizar as aulas que foram ministradas na disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, da Universidade Federal de Viçosa, pelo professor Emerson Medeiros Del Ponte. Espero que aproveite o conteúdo!!"
  },
  {
    "objectID": "Aula_8.html",
    "href": "Aula_8.html",
    "title": "Aula 8",
    "section": "",
    "text": "Pacotes utilizados no decorrer do código.\n\nlibrary(gsheet) # Importar banco de dados\nlibrary(tidyverse) # Manipulação de dados\nlibrary(patchwork) # Organização de gráficos\nlibrary(performance) # Teste premissas\nlibrary(emmeans) # Comparações multiplas\nlibrary(multcomp)\nlibrary(knitr) #Tabelas\nlibrary(epifitter) # Para calcular a AACPD"
  },
  {
    "objectID": "Aula_8.html#anova",
    "href": "Aula_8.html#anova",
    "title": "Aula 8",
    "section": "Anova",
    "text": "Anova\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = dados)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA ANOVA indicou que existe pelo menos um par de médias entre os tratamentos que se diferem entre si, pelo teste F, ao nível de 5% de probabilidade."
  },
  {
    "objectID": "Aula_8.html#premissas",
    "href": "Aula_8.html#premissas",
    "title": "Aula 8",
    "section": "Premissas",
    "text": "Premissas\nAgora vamos verificar as premissas para saber se podemos seguir com as análises.\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\n\nPremissas atendidas!"
  },
  {
    "objectID": "Aula_8.html#comparações-múltiplas",
    "href": "Aula_8.html#comparações-múltiplas",
    "title": "Aula 8",
    "section": "Comparações múltiplas",
    "text": "Comparações múltiplas\nO teste de comparações múltiplas indicou que os melhores tratamentos foram os tratamentos: 4 5, 6, 7 e 8.\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc) # Apresenta os contrates entre os tratamentos.\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_8.html#anova-1",
    "href": "Aula_8.html#anova-1",
    "title": "Aula 8",
    "section": "Anova",
    "text": "Anova\nA ANOVA indicou que existe pelo menos um par de médias de tratamentos que se diferem entre si, pelo teste F, ao nível de 5% de probabilidade.\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = dados)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Aula_8.html#premissas-1",
    "href": "Aula_8.html#premissas-1",
    "title": "Aula 8",
    "section": "Premissas",
    "text": "Premissas\nOs dados não atenderam as premissas de normalidade dos resíduos e homogeneidade de variâncias. Uma alternativa é realizar a transformação dos dados. No entanto, vamos seguir para o ajuste de GLMs (Modelos Lineares Generalizados).\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008)."
  },
  {
    "objectID": "Aula_8.html#modelo-linear-generalizado-glm",
    "href": "Aula_8.html#modelo-linear-generalizado-glm",
    "title": "Aula 8",
    "section": "Modelo linear generalizado (GLM)",
    "text": "Modelo linear generalizado (GLM)\nNesse método selecionamos o padrão de distribuição dos dados na função para ajuste do modelo, e seguimos com a ANOVA e testes de comparações múltiplas.\n\nm1 &lt;- glm(FER ~ TRAT + BLOCO, \n          family = gaussian,\n          data = dados)\nsummary(m1)\n\n\nCall:\nglm(formula = FER ~ TRAT + BLOCO, family = gaussian, data = dados)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  20.4531     0.9334  21.912 6.00e-16 ***\nTRAT2       -14.3750     1.1257 -12.769 2.30e-11 ***\nTRAT3       -16.2500     1.1257 -14.435 2.25e-12 ***\nTRAT4       -17.1250     1.1257 -15.212 8.20e-13 ***\nTRAT5       -17.0000     1.1257 -15.101 9.45e-13 ***\nTRAT6       -17.2500     1.1257 -15.323 7.13e-13 ***\nTRAT7       -16.8750     1.1257 -14.990 1.09e-12 ***\nTRAT8       -16.7500     1.1257 -14.879 1.26e-12 ***\nBLOCO2       -0.4375     0.7960  -0.550    0.588    \nBLOCO3        0.2500     0.7960   0.314    0.757    \nBLOCO4       -0.6250     0.7960  -0.785    0.441    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.534598)\n\n    Null deviance: 1035.930  on 31  degrees of freedom\nResidual deviance:   53.227  on 21  degrees of freedom\nAIC: 131.09\n\nNumber of Fisher Scoring iterations: 2\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nAnova(m1)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: FER\n      LR Chisq Df Pr(&gt;Chisq)    \nTRAT    386.20  7     &lt;2e-16 ***\nBLOCO     1.51  3     0.6792    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmedias &lt;-  emmeans(m1, ~ TRAT,\n                    type = \"response\")\ncld(medias, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      3.00 0.796 21     1.34     4.66  A    \n 4      3.12 0.796 21     1.47     4.78  A    \n 5      3.25 0.796 21     1.59     4.91  A    \n 7      3.38 0.796 21     1.72     5.03  A    \n 8      3.50 0.796 21     1.84     5.16  A    \n 3      4.00 0.796 21     2.34     5.66  A    \n 2      5.88 0.796 21     4.22     7.53  A    \n 1     20.25 0.796 21    18.59    21.91   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_8.html#anova-2",
    "href": "Aula_8.html#anova-2",
    "title": "Aula 8",
    "section": "Anova",
    "text": "Anova\nExiste pelo menos um par de médias entre tratamentos que se diferem entre si, pelo teste F, ao nível de 5% de probabilidade.\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n               data = dados)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Aula_8.html#premissas-2",
    "href": "Aula_8.html#premissas-2",
    "title": "Aula 8",
    "section": "Premissas",
    "text": "Premissas\nAs premissas foram atendidas!\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542)."
  },
  {
    "objectID": "Aula_8.html#comparações-múltiplas-1",
    "href": "Aula_8.html#comparações-múltiplas-1",
    "title": "Aula 8",
    "section": "Comparações múltiplas",
    "text": "Comparações múltiplas\nSeparando grupos pelo teste de Tukey.\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod) # contrates\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_prod, Letters = LETTERS)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nVisualizando\nValores médios com IC. A sobreposição de intervalos é perceptível, o que condiz para não existir diferença entre os tratamentos, exceto, entre os tratamentos 1 e 6.\n\ndf &lt;- data.frame(medias_prod)\ndf|&gt; \n  ggplot(aes(TRAT, emmean)) + \n  geom_point() + \n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.2) + \n  theme_classic() + \n  ylim(2000, 6000) +\n  labs(x = 'Tratamentos', y = 'Produtividade (kg/ha)') +\n  annotate(geom = 'text', x = 1.2, y = 4300, label = \"A\") +\n  annotate(geom = 'text', x = 2.2, y = 5000, label = \"AB\") +\n  annotate(geom = 'text', x = 3.2, y = 5100, label = \"AB\") +\n  annotate(geom = 'text', x = 4.2, y = 5100, label = \"AB\") +\n  annotate(geom = 'text', x = 5.2, y = 5100, label = \"AB\") +\n  annotate(geom = 'text', x = 6.2, y = 5100, label = \"B\") +\n  annotate(geom = 'text', x = 7.2, y = 5100, label = \"AB\") +\n  annotate(geom = 'text', x = 8.2, y = 5100, label = \"AB\")\n\n\n\n\n\n\n\n\n\n\nTabela\n\ndf_prod &lt;- cld(medias_prod, Letters = LETTERS)\ndf_prod &lt;- as.data.frame(df_prod)\nkable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB"
  },
  {
    "objectID": "Aula_8.html#aacpd",
    "href": "Aula_8.html#aacpd",
    "title": "Aula 8",
    "section": "AACPD",
    "text": "AACPD\nCalculando Área Abaixo da Curva de Progresso da Doença (AACPD).\n\naacpd &lt;- dados |&gt; \n  group_by(Irrigation, rep) |&gt; \n  summarise(AACPD = AUDPC(day, severity))\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\naacpd\n\n# A tibble: 6 × 3\n# Groups:   Irrigation [2]\n  Irrigation   rep AACPD\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Drip           1  13.0\n2 Drip           2  13.9\n3 Drip           3  13.3\n4 Furrow         1  13.5\n5 Furrow         2  14.1\n6 Furrow         3  13.7\n\n\n\nPremissas e ANOVA\n\nm_curve &lt;- lm(AACPD ~ Irrigation + factor(rep),\n               data = aacpd)\ncheck_normality(m_curve)\n\nOK: residuals appear as normally distributed (p = 0.380).\n\ncheck_heteroscedasticity(m_curve)\n\nOK: Error variance appears to be homoscedastic (p = 0.704).\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: AACPD\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNão há diferença entre os tipos de irrigação sobre a AACPD."
  },
  {
    "objectID": "Aula_5.html",
    "href": "Aula_5.html",
    "title": "Aula 5",
    "section": "",
    "text": "Carregando pacotes que serão utilizados no decorrer do código.\n\nlibrary(gsheet) # para importar os dados contidos de uma planilha google \nlibrary(tidyverse) # Utilizado para a manipulação de dados\nlibrary(ggthemes) # para mais opções de temas gráficos\nlibrary(patchwork) # para organização dos gráficos"
  },
  {
    "objectID": "Aula_5.html#histograma",
    "href": "Aula_5.html#histograma",
    "title": "Aula 5",
    "section": "Histograma",
    "text": "Histograma\nAs notas das provas 1 e 2 foram plotadas em histogramas e a média indicada por um linha vertical tracejada. Observa-se que a turma em sua maioria tem notas mais elevadas. Poucos estudantes tiveram notas muito baixas nas provas.\n\np1 &lt;- notas |&gt; \n  filter(prova == 'Prova 1') |&gt; \n  ggplot(aes(nota)) +\n  geom_histogram(bins = 5, color = 'black', fill = 'lightgreen')  +\n  geom_vline(xintercept = mean(notas$nota), linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(y = 'Frequency', x = 'Nota') +\n  theme_clean()+\n  ylim(0, 7)+\n  annotate(geom = 'text',\n           x = 73,\n           y = 7.5,\n           label = 'Mean') +\n  #facet_wrap(~ prova) +\n  theme(legend.position = 'none')\n\np2 &lt;- notas |&gt; \n  filter(prova == 'Prova 2') |&gt; \n  ggplot(aes(nota)) +\n  geom_histogram(bins = 5, color = 'black', fill = 'lightblue')  +\n  geom_vline(xintercept = mean(notas$nota), linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(y = 'Frequency', x = 'Nota') +\n  theme_clean()+\n  ylim(0, 7)+\n  annotate(geom = 'text',\n           x = 73,\n           y = 7.5,\n           label = 'Mean') +\n  #facet_wrap(~ prova) +\n  theme(legend.position = 'none')\n\np1 + p2"
  },
  {
    "objectID": "Aula_5.html#boxplot",
    "href": "Aula_5.html#boxplot",
    "title": "Aula 5",
    "section": "Boxplot",
    "text": "Boxplot\nO boxplot abaixo deixa claro que a distribuição das notas entre as duas provas são bem semelhantes como já observado anteriormente. Com valores de amplitude dos dados, primeiro, segundo e terceiro quartis muito próximos.\n\nnotas |&gt; \n  ggplot(aes(x = prova, y = nota)) +\n  geom_boxplot(fill = 'gray') +\n  geom_jitter(width = 0.1, alpha = 0.7, color = 'darkred', size = 3) +\n  theme_clean() +\n  labs(x = '', y = 'Nota')"
  },
  {
    "objectID": "Aula_5.html#dispersão",
    "href": "Aula_5.html#dispersão",
    "title": "Aula 5",
    "section": "Dispersão",
    "text": "Dispersão\nO gráfico abaixo apresenta a dispersão das notas e indica a percentagem de alunos que tiverem notas abaixo da nota de referência em cada prova aplicada.\nUtilizando a nota de referência hipotética (75), 45,45 % dos alunos tiveram notas abaixo de 75, enquanto na segunda prova, 40,91 % dos alunos tiveram notas abaixo de 75. Indicando melhora das notas entre a primerira e segunda avaliação. Essa diferença, representa que um aluno teve nota maior ou igual a 75 na segunda prova quando comparado a primeira que na prática pode não ser tão significante.\n\np1 &lt;- notas |&gt; \n  filter(prova == 'Prova 1', nota &lt; 75) |&gt; \n  nrow()/ notas |&gt; \n  filter(prova == 'Prova 1') |&gt; nrow() * 100\np1 &lt;- round(p1, 2)\n\n\np2 &lt;- notas |&gt; \n  filter(prova == 'Prova 2', nota &lt; 75) |&gt; \n  nrow()/ notas |&gt; \n  filter(prova == 'Prova 2') |&gt; nrow() * 100\np2 &lt;- round(p2, 2)\n\nnotas |&gt; \n  ggplot(aes(x = prova, y = nota, color = prova)) +\n  geom_jitter(width = 0.2, alpha = 0.6, size = 3) +\n  geom_hline(yintercept = 75, linetype = \"dashed\", color = \"darkgrey\", size = 1) +\n  theme_clean() +\n  labs(x = '', y = 'Nota') +\n  annotate(geom = 'text', \n           x = 1.5, \n           y = 77, \n           label = 'Nota referência (75)') +\n  annotate(geom = 'text', \n           x = 0.7, \n           y = 60, \n           label = paste(p1, '%', sep = ' ')) +\n  annotate(geom = 'text', \n         x = 2.3, \n         y = 60, \n         label = paste(p2, '%', sep = ' ')) +\n  theme(legend.position = 'none')"
  },
  {
    "objectID": "Aula_3.html",
    "href": "Aula_3.html",
    "title": "Aula 3",
    "section": "",
    "text": "Abaixo é apresentado o código para carregamento dos pacotes que são utilizados no decorrer do relatório. Para manipulação dos dados, o tidyverse, um pacote auxiliar para manipulação dos gráficos gerados, o patchwork e por último, o pacote ggthemes para acessar mais opções de themas para os gráficos criados com o pacote ggplot2.\nO pacote tidyverse é basicamente uma biblioteca que, ao carregá-lo, automáticamente é carregado outros pacotes úteis para a manipulação e análise de dados como o dplyr e o ggplot2.\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggthemes)"
  },
  {
    "objectID": "Aula_3.html#utilizando-a-função-summary",
    "href": "Aula_3.html#utilizando-a-função-summary",
    "title": "Aula 3",
    "section": "Utilizando a função summary()",
    "text": "Utilizando a função summary()\nUma outra maneira complementar à exploração dos dados é por meio da sumarização dos dados. Isso pode ser feito utilizando a função ‘summary()’ do próprio pacote base do software R. A função requer um vetor com os valores que se deseja sumarizar. A expressão inserida como argumento na função se refere apenas aos dados de incidência da coluna inc do banco de dados cr. Como resultado é retornado os valores de mínimo, 1° quartil, mediana, média, 3° quartil e máximo. Veja:\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n\nDessa forma, esse resumo dos dados nos diz um pouco de como eles estão distribuidos, ou seja, os valores de incidência estão distribuidos entre 9,5 a 86,71%, média e mediana de 34,89 e 32,5%, respectivamente. O 1° quartil (Q1) de 19,43%, cujo 25% dos valores estão abaixo de 19,43% de incidência e o 3° quartil (Q3) de 48,20%, cujo 75% dos valores estão abaixo de 48,20% de incidência."
  },
  {
    "objectID": "Aula_3.html#visualizar-os-subconjuntos",
    "href": "Aula_3.html#visualizar-os-subconjuntos",
    "title": "Aula 3",
    "section": "Visualizar os subconjuntos",
    "text": "Visualizar os subconjuntos\nAgora, segue-se a criação de gráficos para cada subconjunto gerado anteriormente.\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar, sev2,\n             fill = cultivar)) +\n  geom_boxplot() +\n  scale_fill_few() +\n  theme_few() +\n  labs(y = \"Severidade (%)\",\n       x = \" \",\n       fill = 'Cultivar') + \n  coord_flip()\n\np2 &lt;- cr_pr |&gt; \n  ggplot(aes(cultivar, sev2,\n             fill = cultivar)) +\n  geom_boxplot() +\n  scale_fill_few() +\n  theme_few() +\n  labs(y = \"Severidade (%)\",\n       x = \" \",\n       fill = 'Cultivar')+ \n  coord_flip()\n\np3 &lt;-  cr_oromia |&gt; \n  ggplot(aes(x = sev2)) +\n  geom_histogram() + \n  theme_minimal()\n\np1 &lt;- p1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\nTrês gráficos foram gerados a partir dos subconjutos criados. E agora, utilizando o pacote patchwork vamos agrupar os gráfigos em apenas um:\n\np1 / p2\n\n\n\n\n\n\n\n\nAcima a legenda ficou duplicada. No próprio pacote tem como resolver isso utilizando a função ‘plot_layout()’.\n\n# ?patchwork  # Utiliza para acessar ajuda do pacote e ver suas funções e argumentos.\n\n(p1 / p2) +\nplot_layout(guides = 'collect')\n\n\n\n\n\n\n\n\nAdicionando identificadores nos gráficos utilizando a função ‘plot_annotatin()’ e salvando a imgem utilizando a função ‘ggsave()’ diretamente na pasta ‘Imagens’.\n\n(p1 / p2) +\nplot_layout(guides = 'collect',\n            axes = 'collect') + \n  plot_annotation(tag_levels = 'A',\n                  title = \"Coffe rust in Ethiopia\", \n                  caption = \"Source: Del Ponte (2022).\")\n\n\n\n\n\n\n\nggsave('imagens/aula3-pach1.png', width = 6, height = 8, dpi = 300)"
  },
  {
    "objectID": "Aula_11.html",
    "href": "Aula_11.html",
    "title": "Aula 11",
    "section": "",
    "text": "Utilizando o pacote ggplot2 e o pacote leaflet.\nSeguiremos, a partir de agora, com foco na criação de mapas utilizando o RStudio.\n\n\nInstalando os pacotes rnaturalearthhires e rnaturalearth.\n\n# remotes::install_github(\"ropensci/rnaturalearthhires\")\n# install.packages('rnaturalearthhires', repos = 'http://packages.ropensci.org', type = \"source\")\n# install.packages('rnaturalearth')"
  },
  {
    "objectID": "Aula_11.html#instalação-de-pacotes",
    "href": "Aula_11.html#instalação-de-pacotes",
    "title": "Aula 11",
    "section": "",
    "text": "Instalando os pacotes rnaturalearthhires e rnaturalearth.\n\n# remotes::install_github(\"ropensci/rnaturalearthhires\")\n# install.packages('rnaturalearthhires', repos = 'http://packages.ropensci.org', type = \"source\")\n# install.packages('rnaturalearth')"
  },
  {
    "objectID": "Aula_11.html#mapas-iguais-ao-do-google-maps",
    "href": "Aula_11.html#mapas-iguais-ao-do-google-maps",
    "title": "Aula 11",
    "section": "Mapas iguais ao do Google maps!",
    "text": "Mapas iguais ao do Google maps!\nCriando um gráfico interativo igual ao google maps e inserindo pontos. A função leaflet(), identifica automaticamente dentro do banco de tados sbr as colunas nomeadas com latitude e longitude não precisando identificar quais são. A função addCircleMarkers() insere os pontos de acordo com as coordenadas. O gráfico gerado também é interativo.\n\nleaflet(sbr) |&gt; \n  addTiles() |&gt; \n  #setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; \n  addCircleMarkers(radius = 1)\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\n\n\n\n\n\nTestando outras camadas:\n\nleaflet() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5)"
  },
  {
    "objectID": "Aula_11.html#outro-mapa",
    "href": "Aula_11.html#outro-mapa",
    "title": "Aula 11",
    "section": "Outro mapa",
    "text": "Outro mapa\nMapa do Brasil com distribuição das doenças e presença de cada uma na forma de gráfico de pizza. Os gráficos de pizzas não representam de forma proporcional as ocorrências das doenças, mas sim, a presença.\n\nmapa &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing ')\n\n\nBra_2 &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\", color = \"black\", linewidth = 0.5) +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6),\n                  alpha = 0.8, color = NA, data = mapa,\n                  cols = c (\"DFC\",\n                            \"MA\",\n                            \"FER\",\n                            \"ANTR\",\n                            \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                  size = 2, nudge_x = 0.2, nudge_y = 0.27, color = 'gray30', family = \"Arial\")+\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map()+\n  labs(x = \"Longitude\", y = \"Laititude\", legend = \" \", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(family = \"Arieal\", size = 8))\n\nBra_2\n\n\n\n\n\n\n\n\nAs possibilidades de criação de mapas, utilizando o RStudio, são muitas. Basta uma boa criatividade para utilização dos recursos e mãos a obra!"
  },
  {
    "objectID": "Aula_1.html",
    "href": "Aula_1.html",
    "title": "Aula 1",
    "section": "",
    "text": "Antes de começarmos a desenvolver códigos com foco em análise de dados, vamos iniciar criando um projeto, em R, para que nossos arquivos fiquem salvos e organizados. Para isso, após a instalação dos Softwares R e RStudio, abra o RStudio e siga os passos:\n\n\nConforme a figura, clique no botão “Create a project”:\n\n\n\nFonte: O autor.\n\n\n\n\n\nNa janela que se abrir, clique na opção “New Directory”:\n\n\n\nFonte: O autor.\n\n\n\n\n\nNa nova janela clique em “New Project”\n\n\n\nFonte: O autor.\n\n\n\n\n\nDefina o diretório e clique em ’Creat Project”. Pronto! Seu diretório foi criado. Agora, toda vez que for desenvolver algum código, de um trabalho espefico, salve nesta pasta.\n\n\n\nFonte: O autor.\n\n\n\n\n\nAgora, vá ao diretório que salvou o projeto e clique no arquivo “.Rproj”. Faça isso toda vez que for trabalhar nele. Ao clicar no arquivo do projeto, o ambiente do RStudio será aberto, clique em “New File” &gt; “Quarto Document”. Defina título e autor e clique em “Create”.\n\n\n\nFonte: O autor.\n\n\nVocê acabou de criar um arquivo .qmd e em sua janela terá algo assim:\n\n\n\nFonte: O autor.\n\n\nComo se pode perceber, esse tipo de arquivo permite alternar entre escrita e comandos. Essas caixas de comando são chamadas de chunks e são nelas que inserimos os códigos de interesse. Para criar um novo chunk, use o atalho ctrl + alt + i."
  },
  {
    "objectID": "Aula_1.html#passo",
    "href": "Aula_1.html#passo",
    "title": "Aula 1",
    "section": "",
    "text": "Conforme a figura, clique no botão “Create a project”:\n\n\n\nFonte: O autor."
  },
  {
    "objectID": "Aula_1.html#passo-1",
    "href": "Aula_1.html#passo-1",
    "title": "Aula 1",
    "section": "",
    "text": "Na janela que se abrir, clique na opção “New Directory”:\n\n\n\nFonte: O autor."
  },
  {
    "objectID": "Aula_1.html#passo-2",
    "href": "Aula_1.html#passo-2",
    "title": "Aula 1",
    "section": "",
    "text": "Na nova janela clique em “New Project”\n\n\n\nFonte: O autor."
  },
  {
    "objectID": "Aula_1.html#passo-3",
    "href": "Aula_1.html#passo-3",
    "title": "Aula 1",
    "section": "",
    "text": "Defina o diretório e clique em ’Creat Project”. Pronto! Seu diretório foi criado. Agora, toda vez que for desenvolver algum código, de um trabalho espefico, salve nesta pasta.\n\n\n\nFonte: O autor."
  },
  {
    "objectID": "Aula_1.html#passo-4",
    "href": "Aula_1.html#passo-4",
    "title": "Aula 1",
    "section": "",
    "text": "Agora, vá ao diretório que salvou o projeto e clique no arquivo “.Rproj”. Faça isso toda vez que for trabalhar nele. Ao clicar no arquivo do projeto, o ambiente do RStudio será aberto, clique em “New File” &gt; “Quarto Document”. Defina título e autor e clique em “Create”.\n\n\n\nFonte: O autor.\n\n\nVocê acabou de criar um arquivo .qmd e em sua janela terá algo assim:\n\n\n\nFonte: O autor.\n\n\nComo se pode perceber, esse tipo de arquivo permite alternar entre escrita e comandos. Essas caixas de comando são chamadas de chunks e são nelas que inserimos os códigos de interesse. Para criar um novo chunk, use o atalho ctrl + alt + i."
  },
  {
    "objectID": "Aula_1.html#vetores",
    "href": "Aula_1.html#vetores",
    "title": "Aula 1",
    "section": "Vetores",
    "text": "Vetores\nAté então, o que foi apresentado, de operações matemáticas, uma calculadora simples faz. Vamos agora criar objetos, como vetores e data.frames.\n\na &lt;- 2\nb = 2\n\nO sinal de atribuição “&lt;-” ou “=” utilizado com frequência serve para associar valores a objetos. Como no exemplo acima, o objeto “a” agora vale 2, ou seja, toda vez que chamar este objeto numa operação matemática, será realizado o cálculo com o valor que ele carrega.\n\na + b\n\n[1] 4\n\n\nNo entanto, o objeto criado poderia conter mais que um único valor. Vamos criar agora um vetor:\n\nb &lt;- c(1, 2, 3, 4, 5)\nb\n\n[1] 1 2 3 4 5\n\n\nATENÇÂO: Observe que agora o objeto “b”, antes igual a 2, agora contém os valores inteiros de 1 a 5. Isso acontece porque o valor do objeto “b” foi sobrescrito pelo novo vetor. Dessa forma, b = 2, não existe mais.\nOperações matemáticas podem ser feitas com esse objeto. Por exemplo, vamos realizar uma operação de multiplicação entre os objetos criados.\n\na * b\n\n[1]  2  4  6  8 10\n\n\nNesse caso, observe que cada um dos valores contidos em “b” foi multiplicado pelo valor de “a”. Esse resultado não foi salvo na memória do R, para isso basta adotar o sinal de atribuição.\n\nd &lt;- a * b\nd\n\n[1]  2  4  6  8 10\n\n\nAgora, toda vez que chamar pela variável “d”, retornará o valor da multiplicação.\nUm vetor também pode carregar informações do tipo caracter:\n\nnomes &lt;- c(\"Iago\", \"Klaus\", \"Mariana\", \"David\", \"Gabriel\")\nnomes\n\n[1] \"Iago\"    \"Klaus\"   \"Mariana\" \"David\"   \"Gabriel\""
  },
  {
    "objectID": "Aula_1.html#data-frames",
    "href": "Aula_1.html#data-frames",
    "title": "Aula 1",
    "section": "Data frames",
    "text": "Data frames\nData frames são muito úteis para organizar dados, uma vez que estes permitem que as colunas contenham, por exemplo, valores numéricos ou lógicos ou de caracteres.\nUtilizando a função data.frame(), inserindo os objetos criados, separado-os por vírgula, e atribuindo a um objeto chamado df.\n\ndf &lt;- data.frame(nomes, b, d)\ndf\n\n    nomes b  d\n1    Iago 1  2\n2   Klaus 2  4\n3 Mariana 3  6\n4   David 4  8\n5 Gabriel 5 10\n\n\nEm análise de dados, esse tipo de estrutura é muito utilizado e vamos utilizar bastante no decorrer dessa disciplina de análise."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula_10.html",
    "href": "Aula_10.html",
    "title": "Aula 10",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(AgroR)\nlibrary(drc)\nlibrary(ec50estimator)"
  },
  {
    "objectID": "Aula_10.html#banco-de-dados",
    "href": "Aula_10.html#banco-de-dados",
    "title": "Aula 10",
    "section": "Banco de dados",
    "text": "Banco de dados\nOs dados se referem a medição da severidade de uma determinada doença na cultura da roseira, tomate, café e feijão, utilizando diretentes softwares, Assess, LeafDoctor e ImageJ, para determinar tal severidade.\n\ndados &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992')\n\n\nGráfico\nAbaixo, seguimos com a eleboração de gráficos de dispersão, comparando duas variáveis e ajustando uma reta.\n\np1 &lt;- dados |&gt; \n  ggplot(aes(x = Assess,y = LeafDoctor)) +\n  geom_point(alpha = 0.7, size = 2) + \n  theme_classic() + \n  geom_smooth(method = 'lm', se = F, color = 'red') + \n  labs(y = 'Severidade (%) com Leaf Doctor',\n       x = 'Severidade (%) com Assess')\np2 &lt;- dados |&gt; \n  ggplot(aes(x = Assess, y = ImageJ)) +\n  geom_point(alpha = 0.7, size = 2) + \n  theme_classic() + \n  geom_smooth(method = 'lm', se = F, color = 'red') + \n  labs(y = 'Severidade (%) com ImageJ',\n       x = 'Severidade (%) com Assess')\n\np1 + p2\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nÉ perceptível que existe uma correlação positiva entre os softweres confrontados.\n\n\nMatriz de correlação\nUtilizando a função corgraph() do pacote AgroR é possível criar uma matriz de correalação. Como esperado existe forte correlação positiva entre as severidades mensuradas pelos softwares. Dessa forma, pode-se utilizar qualquer programa para calcular a severidade já que o Assess é pago.\n\nimgs &lt;- dados |&gt; \n  dplyr::select(3:5)\n\ncorgraph(imgs)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\ncor.test(dados$Assess, dados$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  dados$Assess and dados$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor.test(dados$Assess, dados$ImageJ)\n\n\n    Pearson's product-moment correlation\n\ndata:  dados$Assess and dados$ImageJ\nt = 38.383, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9642331 0.9861219\nsample estimates:\n      cor \n0.9776918 \n\n\nOutro pacote interessante que monta uma matriz de correlação é o pacote corrplot.\n\nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.3.3\n\n\ncorrplot 0.92 loaded\n\ncor_img &lt;- cor(imgs)\ncorrplot(cor_img, method = 'square', type = 'lower')"
  },
  {
    "objectID": "Aula_10.html#banco-de-dados-1",
    "href": "Aula_10.html#banco-de-dados-1",
    "title": "Aula 10",
    "section": "Banco de dados",
    "text": "Banco de dados\nRetornamos com banco de dados já utilizados em aulas anteriores. No banco, está contido variáveis respostas de produtividade, DFCs e severidade de ferrugem. O código a seguir, calcula a correlação entre as variáveis de doença e a variável produtividade. Já é de conhecimento comum, que, quanto mais uma cultura sofre danos devido ao ataque de doenças há um reflexo negativo na sua produtividade, ou seja, menor produtividade. Logo, com base nos cálculos a seguir, esperamos que as correlações sejam negativas.\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\ndfc &lt;- cor.test(campo2$PROD, campo2$DFC)\nfer &lt;- cor.test(campo2$PROD, campo2$FER)\ndfc; fer\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$FER\nt = -4.3949, df = 30, p-value = 0.0001277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7999565 -0.3544981\nsample estimates:\n       cor \n-0.6258321 \n\n\nDe fato, as correlações entre as variáveis doenção versus produtividade foram negativas e moderadas.\nO código abaixo, filtra os intervalos de confiança entre as correlações calculadas entre as variáveis de doenças versus produtividade.\n\ndfc$conf.int[1:2]\n\n[1] -0.8388581 -0.4537361\n\nfer$conf.int[1:2]\n\n[1] -0.7999565 -0.3544981"
  },
  {
    "objectID": "Aula_10.html#banco-de-dados-2",
    "href": "Aula_10.html#banco-de-dados-2",
    "title": "Aula 10",
    "section": "Banco de dados",
    "text": "Banco de dados\nSeguimos com banco de dados de estande de plantas para ajuste de modelos.\n\nestande &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555')\n\n\nGráfico\nO gráfico abaixo, apresenta a dispersão dos dados e duas curvas, uma quadrática e outra linear aos dados. Veja:\n\nestande |&gt; \n  filter(exp == 2) |&gt; \n  ggplot(aes(trat, nplants)) +\n  geom_point() + \n  ylim(0, 100) +\n  geom_smooth(method = 'lm', se = F, formula = y ~ poly(x, 2), color = 'black') +\n  geom_smooth(method = 'lm', se = F) + \n  theme_classic() + \n  labs(y = 'Plants number',\n       x = 'Treatments')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nAjuste de modelo linear de 1° grau\nNa função lm(), ajustamos um modelo linear de primeira ordem, veja:\n\nexp2 &lt;- estande |&gt; \n  filter(exp == 2)\nlm2 &lt;-  lm(nplants ~trat, data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n\n\n\nAjuste de modelo linear de 2° grau\nObserve que foi criada mais uma coluna com valores elevados ao quadrado. No modelo, a variável elevada é acrescida por meio de simbolo “+”. Seguimos com um resumo do modelo, utilizando a função summary(), onde verificamos os valores dos coeficientes da regressão e seu intercepto. Posteriormente, calculou-se o Critério de Akaike, pela função AIC(), É muito útil para comparar diferentes modelos e selecionar o melhor. Significa dizer que, quanto menor o valor de AIC, melhor é o modelo.\n\nexp2$trat2 &lt;- exp2$trat^2\n\nlm3 &lt;- lm(nplants ~ trat + trat2, data = exp2)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nA função, polynomial(), do pacote AgroR, em conjunto com o código abaixo permite plotar a curva ajustada ao grau de interesse, com os pontos e a equação. Veja:\n\nwith(exp2, polynomial(trat, nplants, grau = 2)) \n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]"
  },
  {
    "objectID": "Aula_10.html#banco-de-dados-3",
    "href": "Aula_10.html#banco-de-dados-3",
    "title": "Aula 10",
    "section": "Banco de dados",
    "text": "Banco de dados\nO próximo banco de dados que iremos utilizar a seguir, refere-se a dados de sensibilidade a fungicidas.\n\ngerminacao &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652')"
  },
  {
    "objectID": "Aula_10.html#gráfico-2",
    "href": "Aula_10.html#gráfico-2",
    "title": "Aula 10",
    "section": "Gráfico",
    "text": "Gráfico\n\ngerm &lt;- germinacao |&gt; \n  group_by(code, state, dose) |&gt; \n  dplyr::select(-replicate) |&gt; \n  summarise(mean_germ = mean(germination), .groups = 'drop')\n\ngerm |&gt; \n  ggplot(aes(dose, mean_germ)) + \n  geom_point() +\n  facet_wrap(~code) + \n  geom_smooth(method = 'lm', se = F, formula = y ~ poly(x, 2))\n\n\n\n\n\n\n\n\nSensibilidade a fungicida dos isolados por estado:\n\ngerm |&gt; \n  ggplot(aes(dose, mean_germ)) + \n  geom_point() +\n  facet_wrap(~state) + \n  geom_smooth(method = 'lm', se = F, formula = y ~ poly(x, 2))"
  },
  {
    "objectID": "Aula_10.html#ajuste-do-modelo",
    "href": "Aula_10.html#ajuste-do-modelo",
    "title": "Aula 10",
    "section": "Ajuste do modelo",
    "text": "Ajuste do modelo\nNo código abaixo, utilizamos a dunção drm() do pacote drc, para ajutar modelos não lineares. O argumento fct = permite que seja inserido qual modelo não linear seja ajustado. Para mais sobre o uso da função execute o comando no console: ?drm.\n\nisolado.x &lt;- germ |&gt; \n  filter(code == 152)\n\ndrc1 &lt;- drm(mean_germ ~ dose, data = isolado.x, fct = LL.3())\nAIC(drc1)\n\n[1] 32.57898\n\nplot(drc1)\n\n\n\n\n\n\n\nED(drc1, 50, interval = 'delta')\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.444356   0.077789 0.196796 0.691916\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  5.526512   7.765348  0.7117 0.5280076    \nd:(Intercept) 45.250173   1.876343 24.1162 0.0001563 ***\ne:(Intercept)  0.444356   0.077789  5.7123 0.0106434 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.65351 (3 degrees of freedom)"
  },
  {
    "objectID": "Aula_10.html#determinação-da-ec50",
    "href": "Aula_10.html#determinação-da-ec50",
    "title": "Aula 10",
    "section": "Determinação da EC50",
    "text": "Determinação da EC50\nA determinação da EC50 é muito utilizada quando se trabalha com produtos destinados ao manejo de pragas e doenças. Corresponde a concentração do produto capaz de inibir 50%, por exemplo, da população, do desenvolvimento de um fungo ou no índice de germinação de esporos.\nUm pacote que já possui funções para realizar esses cálculos é o pacote ec50estimator, com a função estimate_EC50(). Nesse caso, determinou-se a EC50 sobre a germinação de esporos para cada isolado, com ajuste de modelo logístico no argumento fct =. Com base no resultado conseguimos identificar que o isolado FGT05 foi o mais sensível ao fungicida testado.\n\ndf_ec50 &lt;- estimate_EC50(mean_germ ~ dose,\n                         data = germ,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc ::LL.3())\ndf_ec50 |&gt; \n  arrange(Estimate)\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1  FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n2  FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n3    169        0.14722311 0.009555688  0.116812646 0.1776336\n4  FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n5    188        0.15297172 0.004284691  0.139335920 0.1666075\n6  FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n7    153        0.20379664 0.042373512  0.068945217 0.3386481\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9  FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n10 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n11   170        0.37503889 0.043207328  0.237533889 0.5125439\n12   152        0.44435629 0.077789240  0.196796213 0.6919164\n13 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n14 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n15   164        0.50775844 0.047248266  0.357393370 0.6581235\n16   189        0.53106193 0.023130936  0.457448972 0.6046749\n17 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n18   165        0.55839613 0.114195113  0.194976315 0.9218159\n19   186        0.57975744 0.013332268  0.537328208 0.6221867\n20 FGT07        0.88770053 0.079917704  0.633366725 1.1420343"
  },
  {
    "objectID": "Aula_2.html",
    "href": "Aula_2.html",
    "title": "Aula 2",
    "section": "",
    "text": "O foco para esse documento é apresentar a importância e o procedimento de importação de dados. Além disso, demonstrar uma breve explicação sobre elaboração de gráficos e como salvá-los.\n\nPacotes\nCarregamento dos pacotes necessários para execução dos códigos desse documento. O pacote ec50estimator, será utilizado para acessarmos seu banco de dados denominado “multi_isolate”. O pacote readxl, será utilizado para importação de dados a partir de arquivos “.xlsx”. O pacote tidyverse, será utilizado para auxiliar na manipulação de dados. Por último, o pacote gsheet, será utilizado para importar dados de planilhas onlines.\n\nlibrary(ec50estimator)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(gsheet)\n\n\n\nImportação de dados\nA importação de dados é uma etapa fundamental que precede a análise dos dados. Existem diversas maneiras para importar dados para o software RStudio. Por exemplo, os dados podem ser oriundos de pacotes (ex. ec50estimator), de planilhas (.xlsx), de arquivos de texto (.csv), diretamente de um arquivo da internet (planilhas onlines como as planilhas google) ou, não muito usual, criar objetos que carreguem os dados e montar um data frame.\n\ndf1 &lt;- multi_isolate # Banco de dados do pacote ec50estimator\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\") # Pacote readxl\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = 2) # Pacote readxl\ndf3 &lt;- read_csv(\"dados-diversos.csv\") # Pacote readr\ndf4 &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137') # Pacote gsheet\n\n\n\nConstruindo um gráfico\nOs gráficos são fortes aliados das pessoas que trabalham com análise de dados. A visualização por meio de gráficos consiste em um dos primeiros passos para a análise exploratória após a importação. Os dados, em forma gráfica, permite visualizar tendências ou padrãos mais facilmente, o que auxilia o pesquisador a definir como seguir com sua abordagem exploratória. O que não seria uma fácil tarefa apenas observando os dados planilhados.\nOs dados para construção do gráfico são de um ensaio com Delineamento Experiental Inteiramente Casualisado (DIC), com 2 tratamentos (Mg2 e Controle), 10 repetições e apenas uma variável resposta (comp). Uma maneira de visualizar esses dados é por meio de gráfico boxplot onde cada um representa um tratamento. Por meio da gráfico conseguimos perceber que existe uma diferença entre os tratamentos, com valores de comp maiores para o tratamento controle do que o tratamento com Mg2. Por outra perspectiva, numericamente, o tratamento com Mg2 foi capaz de reduzir o valor da variável comp em relação ao controle.\nO código abaixo gera um gráfico boxplot:\n\ndf2 |&gt; \n  ggplot(aes(x = trat, y = comp)) +\n  geom_boxplot(outlier.color = NA, fill = \"green\") +\n  geom_jitter(width = 0.05,\n              color = 'black',\n              shape = 5,\n              size = 2) + \n  theme_classic() + \n  labs(x = 'Tratamento',\n       y = 'Comprimento (mm)',\n      title = 'Meu primeiro ggplot',\n      caption = 'Fonte: Dados diversos') +\n  scale_y_continuous(limits = c(5, 20),\n                     n.breaks = 4) \n\n\n\n\n\n\n\n\n\n\nSalvando o gráfico\nApós a criação de alguma figura, as vezes é interessante salvá-la para usos posteriores. O pacote ggplot2 possui uma função destinada para isso, chama-se ggsave(). Com ela é possível salvar o gráfico gerado em um destino que pode ser especificado, assim como dimenções, resolução, formato de saída entre outras configurações que podem ser acessadas buscando ajuda (digite no console: ‘?ggsave’). Agora, retornando para salvar o gráfico gerado, na função ggsave(), determinamos o nome que queremos para a figura, assim como a cor de fundo especificada pelo argumento ‘bg =’. Ao executar o código a imagem é salva altomaticamente em seu diretório de trabalho.\n\nggsave(filename = \"imagens/plot1.png\", bg = \"white\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "Aula_4.html",
    "href": "Aula_4.html",
    "title": "Aula 4",
    "section": "",
    "text": "Os pacotes necessários neste documento seguem abaixo. Dentre os pacotes carregados, há um que ainda não foi utilizado, o pacote janitor. O janitor é um pacote que possui funções destinadas a limpar base de dados, por exemplo, para nomes de colunas muito complexos, ele os transforma para um formato mais simplificado. Para entender mais sobre o pacote e suas funções clique aqui.\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggthemes)\nlibrary(gsheet)"
  },
  {
    "objectID": "Aula_4.html#importando-banco-de-dados",
    "href": "Aula_4.html#importando-banco-de-dados",
    "title": "Aula 4",
    "section": "Importando banco de dados",
    "text": "Importando banco de dados\n\nColando um vetor\nSelecione o conjunto de dados que se deseja colar, clique na opção Addins, na seção DATAPASTA clique em paste as vactor. Automaticamente, seus dados serão colados dentro da função concatenar (“c()”). Caso queira que a colagem dos dados seja na vertical, há a opção paste as vector (vertical).\n\ncomp &lt;- c(9, 125, 10, 8, 132, 11, 108, 95, 108, 104, 1372, 1591, 157, 142, 159, 1654, 18, 144, 1641, 16)\n\n\n\nColando um dataframe\nPara data frames, a ideia é semelhante. Crie um objeto para receber os dados, selecione os dados que queira colar e na opção Addins clique no botão paste as data.frame.\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE,\n                    trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\n                             \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                             \"control\",\"control\",\"control\",\"control\",\n                             \"control\",\"control\",\"control\",\"control\",\"control\",\n                             \"control\"),\n                     rep = c(1L,2L,3L,4L,5L,\n                             6L,7L,8L,9L,10L,1L,2L,3L,4L,5L,6L,7L,\n                             8L,9L,10L),\n                    comp = c(9,125,10,8,132,\n                             11,108,95,108,104,1372,1591,157,142,159,\n                             1654,18,144,1641,16)\n      )\n\n\n\nA tibble\nÉ como um data frame com algumas funcionalidades a mais. Por exemplo, elas não mudam automaticamente os dados das colulas de strings para fatores. Elas podem conter culunas mais complexas como colunas de listas. Uma impressão dos dados que não sobrecarrega o console. Para colagem desse tipo de dados, semelhante ao passo anterior, procure em Addins a opção referente a colagem de tibble.\n\ndat2 &lt;- \n  tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,   125,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,   132,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,   108,\n      \"Mg2\",   8L,    95,\n      \"Mg2\",   9L,   108,\n      \"Mg2\",  10L,   104,\n  \"control\",   1L,  1372,\n  \"control\",   2L,  1591,\n  \"control\",   3L,   157,\n  \"control\",   4L,   142,\n  \"control\",   5L,   159,\n  \"control\",   6L,  1654,\n  \"control\",   7L,    18,\n  \"control\",   8L,   144,\n  \"control\",   9L,  1641,\n  \"control\",  10L,    16\n  )\n\nColagem de dados de cotação de preço da saca de café de 60Kg do Centro de Comércio de Café de Vitória (CCCV). Os dados abaixo, foram selecionados de uma planilha de um site da web e colado junto ao código utilizando as funcionalidas já descritas do pacote DATAPASTA.\n\nvisitas &lt;- tibble::tribble(\n                       ~`Dia`, ~`Arábica  Tipo 6`, ~`Arábica Tipo 7`, ~`Conilon Tipo 7/8`,\n                        \"1\",  \"965,00\",  \"860,00\",  \"813,00\",\n                        \"2\",       \"-\",       \"-\",       \"-\",\n                        \"3\",       \"-\",       \"-\",       \"-\",\n                        \"4\",  \"973,00\",  \"873,00\",  \"822,00\",\n                        \"5\",  \"964,00\",  \"859,00\",  \"820,00\",\n                        \"6\",  \"973,00\",  \"861,00\",  \"825,00\",\n                        \"7\",  \"992,00\",  \"878,00\",  \"850,00\",\n                        \"8\",  \"985,00\",  \"866,00\",  \"848,00\",\n                        \"9\",       \"-\",       \"-\",       \"-\",\n                       \"10\",       \"-\",       \"-\",       \"-\",\n                       \"11\",  \"967,00\",  \"859,00\",  \"836,00\",\n                       \"12\",  \"970,00\",  \"863,00\",  \"839,00\",\n                       \"13\",  \"962,00\",  \"864,00\",  \"839,00\",\n                       \"14\",  \"965,00\",  \"857,00\",  \"847,00\",\n                       \"15\",  \"965,00\",  \"856,00\",  \"849,00\",\n                       \"16\",       \"-\",       \"-\",       \"-\",\n                       \"17\",       \"-\",       \"-\",       \"-\",\n                       \"18\",  \"967,00\",  \"859,00\",  \"860,00\",\n                       \"19\",  \"968,00\",  \"860,00\",  \"861,00\",\n                       \"20\",  \"968,00\",  \"858,00\",  \"864,00\",\n                       \"21\",  \"975,00\",  \"864,00\",  \"870,00\",\n                       \"22\",  \"983,00\",  \"866,00\",  \"873,00\",\n                       \"23\",       \"-\",       \"-\",       \"-\",\n                       \"24\",       \"-\",       \"-\",       \"-\",\n                       \"25\",  \"984,00\",  \"872,00\",  \"876,00\",\n                       \"26\",  \"991,00\",  \"873,00\",  \"889,00\",\n                       \"27\",       \"-\",       \"-\",       \"-\",\n                       \"28\",       \"-\",       \"-\",       \"-\",\n                       \"29\",       \"-\",       \"-\",       \"-\",\n                       \"30\",       \"-\",       \"-\",       \"-\",\n                       \"31\",       \"-\",       \"-\",       \"-\",\n             \"Média Mensal\",  \"973,17\",  \"863,78\",  \"848,94\"\n             )\n\nBanco de dados do pacote r4pde.\n\npepper &lt;- \n  tibble::tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\nTransformando o dataframe ‘pepper’ do formato largo para o formato longo utilizando a função pivot_longer() e criando um gráfico com ggplot2 e criando anotações.\n\npepper |&gt; \n  pivot_longer(2:4, names_to = 'epidemic', \n               values_to = 'inc') |&gt; \n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() + \n  geom_line(size = 1) + \n  annotate(geom = 'text',\n           x = 10,\n           y = 0.75,\n           label = '1') +\n  annotate(geom = 'text',\n         x = 25,\n         y = 0.75,\n         label = '2') +\n  annotate(geom = 'text',\n           x = 45,\n           y = 0.75,\n           label = '3') +\n  theme(legend.position = 'none') # elimina a legenda do gráfico\n\n\n\n\n\n\n\n\nObserve que cada uma das curvas está sendo identificada, além da cor, por um número. A inserção desses números foi feita utilizando a função annotate() do ggplot2. Como se pode obeservar no código, a função requer o preenchimento de alguns argumentos basícos, como posição do texto nos eixos x e y e o texto a ser inserido. Lembrando que no argumento “label =” a informação a ser apresentada no gráfico deve ser digitado entre áspas simples ou duplas (isso é um indicativo de caracter)."
  },
  {
    "objectID": "Aula_6-7.html",
    "href": "Aula_6-7.html",
    "title": "Aula 6 e 7",
    "section": "",
    "text": "Aprender a realizar Análise de Variância (ANOVA) e testar suas premissas, testes de comparações múltiplas, transformações de dados, testes não-paramétricos, Modelos Lineares Generalizados (GLMs) e Anova Fatorial."
  },
  {
    "objectID": "Aula_6-7.html#gráfico",
    "href": "Aula_6-7.html#gráfico",
    "title": "Aula 6 e 7",
    "section": "Gráfico",
    "text": "Gráfico\nVisualizando os dados dos tratamentos por meio de Boxplot. Já é possível inferir que há diferença entre os tratamentos. Para ter certeza se essa diferença realmente existe, vamos seguir analisando.\n\ndados |&gt; \n  ggplot(aes(trat, comp)) +\n  geom_boxplot(fill = 'lightblue') + \n  labs(x = 'Treatments') +\n  theme_classic() +\n  labs(y = 'Comprimento')"
  },
  {
    "objectID": "Aula_6-7.html#teste-t-de-student",
    "href": "Aula_6-7.html#teste-t-de-student",
    "title": "Aula 6 e 7",
    "section": "Teste t de Student",
    "text": "Teste t de Student\nO teste t de Student é um teste de análise paramétrica e pode ser dividido em três tipos:\n\nTeste t de amostras independentes: Quando se deseja comparar diferença entre médias de dois tratamentos;\nTeste t de amostras dependentes ou pareadas: Quando se deseja comparar diferenças sobre um mesmo grupo antes e depois da aplicação do tratamento;\nTeste t de uma amostra: Quando se deseja comparar a média do grupo com uma determinado valor conhecido.\n\nReestruturando banco de dados para o formato largo e realizando o teste t utilizando as funções pivot_wider() e t.test() dos pacotes tidyr e stats, respectivamente. Por fim, a função report(), do pacote report, retorna um resumo do resultado do teste. De maneira geral, o teste apresentou diferença significativa entre os dois tratamentos com p-valor &lt; 0,05.\n\ndados &lt;- dados |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n\nteste &lt;- t.test(dados$Mg2, dados$control)\nreport(teste)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between dados$Mg2 and\ndados$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect\nis negative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])"
  },
  {
    "objectID": "Aula_6-7.html#premissas",
    "href": "Aula_6-7.html#premissas",
    "title": "Aula 6 e 7",
    "section": "Premissas",
    "text": "Premissas\nAntes de prosseguir com análise paramétrica dos dados, é necessário que os dados atendam as premissas de Normalidade dos Dados e Homogeneidade de Variâncias.\n\nNormalidade\nO teste de normalidade adotado aqui é o teste de Shapiro-Wilk. Existem outros testes de normalidade que podem ser utilizados. No entanto, esse teste é considerado o mais poderoso entre os testes. Pode ser feito da seguinte maneira:\n\nshapiro.test(dados$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados$Mg2\nW = 0.97269, p-value = 0.9146\n\n\n\nshapiro.test(dados$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados$control\nW = 0.93886, p-value = 0.5404\n\n\nObserve que a normalidade foi testada para cada tratamento e o p-valor &gt; 0,05. Dessa maneira, não se rejeita a hipótese nula (H0), que os dados são normais.\n\nGráfico de normalidade\nO código abaixo, apresenta graficamente a normalidade dos dados. Nesse caso, testamos a normalidade para o vetor de valores do tratamento Mg. A interpretação do gráfico é que quanto mais próximo os pontos estão da reta, ou, quanto menor esse erro dos pontos em relação a reta, mais próximo da normalidade estão os dados.\n\nqqnorm(dados$Mg2)\nqqline(dados$Mg2)\n\n\n\n\n\n\n\n\n\n\n\nHomogeneidade de variâncias\nA função var.test() do pacote stats pode ser utilizada para análise de variâncias. A função pede como argumento basicamente 2 vetores numéricos, cada um com os valores da variável resposta de cada um dos tratamentos.\n\nvar.test(dados$Mg2, dados$control)\n\n\n    F test to compare two variances\n\ndata:  dados$Mg2 and dados$control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\n\nCaso as variâncias não sejam homogêneas, pode-se acrescentar o argumento:\n\nt.test(dados$Mg2, dados$control, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  dados$Mg2 and dados$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\nAcabamos de verificar as premissas de normalidade dos dados e homogeneidade das variâncias."
  },
  {
    "objectID": "Aula_6-7.html#gráfico-1",
    "href": "Aula_6-7.html#gráfico-1",
    "title": "Aula 6 e 7",
    "section": "Gráfico",
    "text": "Gráfico\n\ndados2 |&gt; \n  ggplot(aes(assessment, acuracia)) +\n  geom_boxplot(fill = 'lightblue') + \n  labs(y = \"Acurácia\",\n       x = 'Avaliação') +\n  theme_classic() +\n  theme(text = element_text(size = 15))"
  },
  {
    "objectID": "Aula_6-7.html#teste-t-pareado",
    "href": "Aula_6-7.html#teste-t-pareado",
    "title": "Aula 6 e 7",
    "section": "Teste t pareado",
    "text": "Teste t pareado\nSeguindo o mesmo raciocínio utilizado no banco de dados anterior, para este, também será ajustado para o formato largo antes de seguir com a análise.\nPara realizar o teste entre grupos pareados (dependentes), basta acrescentar o argumento paired = TRUE dentro da função t.test().\n\ndados2 &lt;- dados2 |&gt; \n  dplyr::select(rater, assessment, acuracia)\n\ndados2 &lt;-  dados2 |&gt; \n  pivot_wider(names_from = assessment, values_from = acuracia)\n\n\nt.test(dados2$Unaided, dados2$Aided1, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  dados2$Unaided and dados2$Aided1\nt = -4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3552353 -0.1147647\nsample estimates:\nmean difference \n         -0.235 \n\n\nO p-valor &lt; 0,05, rejeita-se H0 e aceita-se a hipótese alternativa (Ha), ou seja, existe diferença significativa entre os grupos de médias ao nível de 5% de probabilidade, pelo teste t pareado. Agora, é preciso verificar as premissas antes de aceitar este resultado como verdade."
  },
  {
    "objectID": "Aula_6-7.html#premissas-1",
    "href": "Aula_6-7.html#premissas-1",
    "title": "Aula 6 e 7",
    "section": "Premissas",
    "text": "Premissas\n\nNormalidade\n\nshapiro.test(dados2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(dados2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados2$Aided1\nW = 0.92852, p-value = 0.4335\n\n\nPelo menos um dos grupos não apresentou normalidade dos dados.\n\n\nHomogeneidade de variâncias\n\nvar.test(dados2$Unaided, dados2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  dados2$Unaided and dados2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nAs variâncias não podem ser consideradas homogêneas. P-valor &gt; 0,05. Os dados foram submetidos a transformações e mesmo assim não atenderam as premissas. Nesse caso, para prosseguir com a análise dos dados é preciso partir para análise não paramétrica, que será abordada mais adiante.\nNo entanto, supondo que os dados são normais e apenas a premissa de homogeneidade de variâncias não foi atendida, pode-se seguir com a análise do teste t indicando o argumento var.equal = FALSE dentro da função t.test(). Esse teste é uma variação do teste t e é conhecido com teste t de Welch.\n\nt.test(dados2$Unaided, dados2$Aided1, paired = TRUE, var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  dados2$Unaided and dados2$Aided1\nt = -4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3552353 -0.1147647\nsample estimates:\nmean difference \n         -0.235"
  },
  {
    "objectID": "Aula_6-7.html#wilcoxon-signed-rank",
    "href": "Aula_6-7.html#wilcoxon-signed-rank",
    "title": "Aula 6 e 7",
    "section": "Wilcoxon Signed-Rank",
    "text": "Wilcoxon Signed-Rank\nEsse teste é uma alternativa não-paramétrica para análise de dados pareados que não apresentam normalidade. Utilizando a função wilcox.test() e definindo o argumento paired = TRUE“.\n\nwilcox.test(dados2$Aided1,\n            dados2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  dados2$Aided1 and dados2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\nO p-valor &lt; 0,05, indicando que existe diferença entre os tratamentos pelo referido teste."
  },
  {
    "objectID": "Aula_6-7.html#gráfico-2",
    "href": "Aula_6-7.html#gráfico-2",
    "title": "Aula 6 e 7",
    "section": "Gráfico",
    "text": "Gráfico\n\ndados3 |&gt; \n  ggplot(aes(especie, tcm)) +\n  geom_boxplot(fill = 'grey') +\n  geom_jitter(width = 0.1, size = 2.5, alpha = 0.7, color = 'darkred') +\n  labs(x = 'Espécies') +\n  theme_classic()"
  },
  {
    "objectID": "Aula_6-7.html#anova",
    "href": "Aula_6-7.html#anova",
    "title": "Aula 6 e 7",
    "section": "ANOVA",
    "text": "ANOVA\nA ANOVA (Análise de Variância), identifica a existência de pelo menos uma média com diferença significativa entre as demais. No entanto, ela por si só, não indica quais médias são diferentes entre si. A hipótese testada é que as médias são iguais. O quadro de ANOVA retorna o p-valor e este sendo menor que o nível de significancia adotado pelo pesquisador, rejeita-se a H0 e aceita-se a Ha. Para realizar essa análise no R, pode-se seguir com as funções anova() e lm() do pacote stats. Para entender melhor sobre como utilizar essas funções e seus argumentos, busque ajuda digitando no console ?NOME DA FUNÇÃO.\n\nanova(lm(tcm ~ especie, data = dados3))\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO resultado do Quadro da ANOVA indicou que existe pelo menos uma média, entre os tratamentos, que se diferem entre si ao nível de 5% de significância."
  },
  {
    "objectID": "Aula_6-7.html#teste-de-comparações-múltiplas",
    "href": "Aula_6-7.html#teste-de-comparações-múltiplas",
    "title": "Aula 6 e 7",
    "section": "Teste de comparações múltiplas",
    "text": "Teste de comparações múltiplas\nUtilizando a função emmeans() e cld() para separar os grupos de médias estatisticamente diferentes entre si.\n\nm1 &lt;- lm(tcm ~ especie, data = dados3)\nmedias1 &lt;-  emmeans(m1, ~ especie)\ncld(medias1, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_6-7.html#premissas-normalidades-dos-resíduos",
    "href": "Aula_6-7.html#premissas-normalidades-dos-resíduos",
    "title": "Aula 6 e 7",
    "section": "Premissas: normalidades dos resíduos",
    "text": "Premissas: normalidades dos resíduos\nA seguir, três maneiras de verificar as premissas.\n\nPrimeira maneira: Utilizando as funções shapiro.test() e bartlett.test().\n\nOs resíduos são normais e as variâncias são homeogêneas.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = dados3)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\n\nSegunda maneira: Realizando o plot do resultado da função simulateResiduals() do modelo ajustado, nesse caso, ‘m1’. Os resíduos são normais e as variências homogêneas.\n\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\n\nTerceira maneira: Utilizando aa fuções check_normality() e check_heteroscedasticity() do pacote Performance, para verificar a normalidade dos resíduos e homeogeneidade das variâncias, respectivamente.\n\n\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\nplot &lt;- check_model(m1)"
  },
  {
    "objectID": "Aula_6-7.html#gráfico-3",
    "href": "Aula_6-7.html#gráfico-3",
    "title": "Aula 6 e 7",
    "section": "Gráfico",
    "text": "Gráfico\nApenas com base no gráfico abaixo, podemos inferir que existe tratamentos que diferem entre si sobre a variável contagem. Vamos realizar os teste estatísticos para ter certeza disso.\n\ninsects |&gt; \n  ggplot(aes(x = spray, y = count)) +\n  geom_boxplot(outlier.colour = NA, fill = 'lightblue') +\n  geom_jitter(width = 0.05, color = 'gray') + \n  labs(x = 'Spray', y = 'Contagem') +  \n  theme_classic()"
  },
  {
    "objectID": "Aula_6-7.html#anova-1",
    "href": "Aula_6-7.html#anova-1",
    "title": "Aula 6 e 7",
    "section": "ANOVA",
    "text": "ANOVA\nEsses dados são referentes a um ensaio realizado em Delineamento Inteiramente Casualizado (DIC). Logo, o ajuste do modelo, para rodar a ANOVA, é simples. Como apresentado no código abaixo:\n\nml &lt;- lm(count ~ spray, \n         data = insects)\nanova(ml)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO p-valor &lt; 0,05, ou seja, existe pelo menos um par de médias que se diferem entre si, pelo teste F, ao nível de 5% de probabilidade."
  },
  {
    "objectID": "Aula_6-7.html#gráfico-histograma-dos-resíduos",
    "href": "Aula_6-7.html#gráfico-histograma-dos-resíduos",
    "title": "Aula 6 e 7",
    "section": "Gráfico: Histograma dos resíduos",
    "text": "Gráfico: Histograma dos resíduos\nCom base no gráfico abaixo, é perceptível que os resíduos têm uma distribuição normal. Seguimos agora com um teste de normalidade para confirmar essa ideia.\n\ninsects |&gt; \n  ggplot(aes(x = ml$residuals)) +\n  geom_histogram(bins = 10, color = 'white', fill = 'lightblue') + \n  labs(x = 'Resíduos') +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nshapiro.test(ml$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ml$residuals\nW = 0.96006, p-value = 0.02226\n\n\nO teste indica não normalidade dos dados, apesar de visualmente o histograma apresentar uma certa normalidade. Vale lembrar que a homogeneidade das variâncias é mais importanque que a normalidade dos resíduos.\n\nbartlett.test(count ~ spray, \n              data = insects)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\nDe acordo com o teste de Bartlett os dados possuem variâncias heterogêneas. Resumindo, não é possível aplicar estatística paramétrica. Parte-se agora para transformação de dados para verificar se é possível trabalhar com estatística paramétrica com esses dados.\nQuando os dados são de contagem, normalmente a transformação com base na raiz quadrada é interessante."
  },
  {
    "objectID": "Aula_6-7.html#alternativa-1-transformação",
    "href": "Aula_6-7.html#alternativa-1-transformação",
    "title": "Aula 6 e 7",
    "section": "Alternativa 1: transformação",
    "text": "Alternativa 1: transformação\n\nTransformação por raiz quadrada\n\ninsects &lt;- insects |&gt; \n  mutate(count2 = sqrt(count))\n\ninsects |&gt; \n  ggplot(aes(x = spray, y = count2)) +\n  geom_boxplot(fill = 'lightblue') +\n  theme_classic() +\n  labs(y = 'Count \\n (transformação pela raiz quadrada)', x = 'Spray')\n\n\n\n\n\n\n\n\nSeguimos agora para testar as premissas utilizando os dados transformados.\n\nml &lt;- lm(count2 ~ spray,\n         data = insects)\nanova(ml)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Uma maneira de testear as premissas\nshapiro.test(ml$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ml$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = insects)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n# Outra maneira de testar as premissas\ncheck_normality(ml)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(ml)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\nPremissas atendidas com a transformação por raiz quadrada. Partimos para testes de comparações múltiplas:\n\nmedias1 &lt;-  emmeans(ml, ~ spray)\ncld(medias1, Letters = letters)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  a    \n E       1.81 0.181 66    1.447     2.17  ab   \n D       2.16 0.181 66    1.802     2.53   b   \n A       3.76 0.181 66    3.399     4.12    c  \n B       3.88 0.181 66    3.514     4.24    c  \n F       4.02 0.181 66    3.656     4.38    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nConcluimos que os fungicidas C e E são os mais eficazes.\n\n\nTransformação Box-Cox\nOutra maneira de transformar os dados é por meio da transformação de Box-Cox. Para isso, primeiro é preciso encontrar o lambda.\n\nlibrary(MASS)\n\nb &lt;-  boxcox(lm(insects$count + 0.1 ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\nCriando a variável transformada conforme a equação:\n\ny(lambda) = (x^lambda - 1) / lambda.\n\n\ninsects$count3 &lt;- (insects$count ^ lambda - 1) / lambda"
  },
  {
    "objectID": "Aula_6-7.html#alternativa-2-teste-não-paramétrico",
    "href": "Aula_6-7.html#alternativa-2-teste-não-paramétrico",
    "title": "Aula 6 e 7",
    "section": "Alternativa 2: Teste não paramétrico",
    "text": "Alternativa 2: Teste não paramétrico\nCaso, após as transformações, os dados ainda não atendam as premissas de normalidade e homogeneidade de variâncias, podemos seguir com análise não-paramétrica. Testes não-paramétricos não consideram as premissas antes testadas e permitem que prossigamos com a análise dos dados.\nO teste de Kruskal-Wallis é um teste não paramétrico similar ao teste F. Portanto, o teste não separa os grupos. Para isso, após o teste apresentar que há pelo menos um par de tratamentos que se diferem estatisticamente entre si, é necessário adotar um teste Post Hoc, para comparações múltiplas. A função kruskal.test(), do pacote stats, realiza essa primeira parte. A função kruskal() do pacote agricolae, realiza essas duas etapas de uma vez. Caso queira, pode-se realizar testes Post Hoc como o teste de Dunn, teste de Nemenyi ou teste de Conover.\n\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n\n\nm3 &lt;- kruskal(insects$count, insects$spray, group = T)\nm3$groups\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c"
  },
  {
    "objectID": "Aula_6-7.html#alternativa-3-modelo-linear-generalizado-glms",
    "href": "Aula_6-7.html#alternativa-3-modelo-linear-generalizado-glms",
    "title": "Aula 6 e 7",
    "section": "Alternativa 3: Modelo linear generalizado (GLMs)",
    "text": "Alternativa 3: Modelo linear generalizado (GLMs)\nOutra alternativa que se pode adotar, para análisar dados que não atenderam as premissas, é realizar ajustes de modelos não lineares, que permite indicar a qual distribuição os dados pertencem. A função glm() do pacote stats, ajusta esses modelos.\n\nm4 &lt;- glm(count ~ spray, \n          family = poisson, # poisson por ser dados de contagem\n          data = insects)\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = insects)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nP-valor &lt; 0,05, um indicativo que existe pelo menos uma média com diferença significativa. Agora para separar os grupos seguimos com testes de comparações múltiplas.\n\nmedias4 &lt;-  emmeans(m4, ~ spray,\n                    type = \"response\")\ncld(medias4, Letters = letters)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  a    \n E      3.50 0.540 Inf      2.59      4.74  ab   \n D      4.92 0.640 Inf      3.81      6.35   b   \n A     14.50 1.099 Inf     12.50     16.82    c  \n B     15.33 1.130 Inf     13.27     17.72    c  \n F     16.67 1.179 Inf     14.51     19.14    c  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_6-7.html#banco-de-dados-1",
    "href": "Aula_6-7.html#banco-de-dados-1",
    "title": "Aula 6 e 7",
    "section": "Banco de dados",
    "text": "Banco de dados\nDados referentes a um ensaio realizado em Delineamento Inteiramente Casualizado (DIC) em esquema fatorial 2x2. O primeiro fator, qualitativo, composto pelos níveis: Líquido iônico e Tebuconazol. O segundo fator, quantitativo, composto pelos níveis: 0,5 e 2. Avaliou-se o efeito dos tratamentos sobre a intensidade de uma doença qualquer.\n\ndados &lt;- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")"
  },
  {
    "objectID": "Aula_6-7.html#gráfico-4",
    "href": "Aula_6-7.html#gráfico-4",
    "title": "Aula 6 e 7",
    "section": "Gráfico",
    "text": "Gráfico\nVisualmente, é perceptível uma diferença do tratamento líquido iônico na concentração de 0,2 com os outros tratamentos.\n\ndados |&gt; \n  ggplot(aes(factor(dose), x = treat, y = severity, color = factor(dose))) + \n  geom_jitter(size = 3, width = 0.2) +\n  theme_classic() + \n  labs(y = 'Severidade (%)', x = ' ', color = 'Doses') +\n  theme(text = element_text(size = 15))"
  },
  {
    "objectID": "Aula_9.html",
    "href": "Aula_9.html",
    "title": "Aula 9",
    "section": "",
    "text": "Carregando pacotes necessários no código.\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(lme4)\nlibrary(car)\nlibrary(DHARMa)\nlibrary(performance)\nlibrary(r4pde)\nlibrary(broom) # para usar a função 'do()'\nlibrary(patchwork)\nlibrary(emmeans)\nlibrary(multcomp)"
  },
  {
    "objectID": "Aula_9.html#gráfico",
    "href": "Aula_9.html#gráfico",
    "title": "Aula 9",
    "section": "Gráfico",
    "text": "Gráfico\n\ndados |&gt; \n  ggplot(aes(method, index)) +\n  geom_jitter(width = 0.1, alpha = 0.5, color = 'black') + \n  facet_wrap(~hybrid) + \n  stat_summary(fun.data = 'mean_cl_boot', color = 'black') + \n  theme_clean()"
  },
  {
    "objectID": "Aula_9.html#modelo-para-subdividida",
    "href": "Aula_9.html#modelo-para-subdividida",
    "title": "Aula 9",
    "section": "Modelo para subdividida",
    "text": "Modelo para subdividida\n\nDados índice de doença\n\ndados &lt;-  dados |&gt; \n  mutate(block = as.factor(block))\n\nmix2 &lt;-  lmer(index ~ hybrid * method + block +(1|block/hybrid),data = dados )\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nPremissas\nPremissa de homogeneidade de variâncias não atendida.\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\n\n\n\nTransformação dos dados\nTransformação por raiz quadrada.\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = dados)\nmix2\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: sqrt(index) ~ hybrid * method + block + (1 | block/hybrid)\n   Data: dados\nREML criterion at convergence: 72.5662\nRandom effects:\n Groups       Name        Std.Dev.\n hybrid:block (Intercept) 0.4644  \n block        (Intercept) 2.2518  \n Residual                 0.3742  \nNumber of obs: 48, groups:  hybrid:block, 24; block, 4\nFixed Effects:\n              (Intercept)             hybrid30F53 YH  \n                  4.65420                   -0.04446  \n              hybrid30K64               hybrid30S31H  \n                 -0.49224                    1.09866  \n            hybrid30S31YH              hybridBG7049H  \n                  0.63521                   -0.58990  \n               methodsilk                     block2  \n                 -0.05317                    0.06156  \n                   block3                     block4  \n                  0.56679                    0.73537  \nhybrid30F53 YH:methodsilk     hybrid30K64:methodsilk  \n                  0.20604                    0.16534  \n  hybrid30S31H:methodsilk   hybrid30S31YH:methodsilk  \n                 -0.91003                   -0.43778  \n hybridBG7049H:methodsilk  \n                  0.01751  \n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0783  3   0.994305   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPremissas atendidas!\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\n\n\n\nTeste de comparações múltiplas\n\nmedias_milho &lt;- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\nmedias_milho\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 11.6 5155     7.35     53.0\n 30F53 YH     24.5 11.5 5155     7.11     52.3\n 30K64        20.3 10.5 5155     4.93     46.1\n 30S31H       37.1 14.2 5155    14.52     70.2\n 30S31YH      31.7 13.1 5155    11.20     62.6\n BG7049H      19.4 10.3 5155     4.50     44.7\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 11.5 5155     7.07     52.2\n 30F53 YH     26.0 11.9 5155     7.95     54.6\n 30K64        21.3 10.8 5155     5.44     47.6\n 30S31H       26.3 12.0 5155     8.11     55.0\n 30S31YH      26.4 12.0 5155     8.16     55.1\n BG7049H      19.1 10.2 5155     4.35     44.3\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\nmedias_milho2\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 11.6 5155     7.35     53.0\n silk       24.4 11.5 5155     7.07     52.2\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 11.5 5155     7.11     52.3\n silk       26.0 11.9 5155     7.95     54.6\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.5 5155     4.93     46.1\n silk       21.3 10.8 5155     5.44     47.6\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.2 5155    14.52     70.2\n silk       26.3 12.0 5155     8.11     55.0\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.1 5155    11.20     62.6\n silk       26.4 12.0 5155     8.16     55.1\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.3 5155     4.50     44.7\n silk       19.1 10.2 5155     4.35     44.3\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 11.5 5155     7.07     52.2  a    \n pin        25.0 11.6 5155     7.35     53.0  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 11.5 5155     7.11     52.3  a    \n silk       26.0 11.9 5155     7.95     54.6  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.5 5155     4.93     46.1  a    \n silk       21.3 10.8 5155     5.44     47.6  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.0 5155     8.11     55.0  a    \n pin        37.1 14.2 5155    14.52     70.2   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.0 5155     8.16     55.1  a    \n pin        31.7 13.1 5155    11.20     62.6  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.2 5155     4.35     44.3  a    \n pin        19.4 10.3 5155     4.50     44.7  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_9.html#dados-de-produtividade",
    "href": "Aula_9.html#dados-de-produtividade",
    "title": "Aula 9",
    "section": "Dados de produtividade",
    "text": "Dados de produtividade\n\nModelo e ANOVA\n\nmix3 &lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), data = dados)\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nPremissas\nPremissas OK!\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\n\n\nTeste de comparações múltiplas\n\ncld(emmeans(mix3, ~ hybrid | method,\n                    type = \"response\"), Letters = letters)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  a    \n 30S31H       8081 743 26.1     6626     9681  ab   \n 30F53 YH     9314 798 26.1     7746    11027  abc  \n 30F53 HX    11130 872 26.1     9410    12995   bc  \n 30K64       11666 893 26.1     9903    13574    c  \n BG7049H     11914 903 26.1    10131    13841    c  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  a    \n 30F53 YH     9079 788 26.1     7532    10770  a    \n 30S31H       9135 790 26.1     7583    10832  a    \n 30F53 HX     9932 824 26.1     8311    11698  ab   \n 30K64       10331 840 26.1     8676    12131  ab   \n BG7049H     12822 936 26.1    10970    14818   b   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula_9.html#dados-do-experimento-1",
    "href": "Aula_9.html#dados-do-experimento-1",
    "title": "Aula 9",
    "section": "Dados do experimento 1",
    "text": "Dados do experimento 1\n\nGráfico\n\nexp1 &lt;-  dados |&gt; \n  filter(exp == 1)\n\nexp1 |&gt; \n  ggplot(aes(x = trat, y = nplants)) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = F)+\n  labs(x = 'Dias', y = 'Estande de plantas')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nAjuste da regressão\nA regressão explica pouco a variação dos dados, visto que o coeficiente de determinação foi muito baixo.\n\nlm1 &lt;- lm(nplants ~ trat, \n          data = exp1)\n\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066"
  },
  {
    "objectID": "Aula_9.html#dados-do-experimento-2",
    "href": "Aula_9.html#dados-do-experimento-2",
    "title": "Aula 9",
    "section": "Dados do experimento 2",
    "text": "Dados do experimento 2\n\nGráfico\n\nexp2 &lt;-  dados |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(x = trat, y = nplants)) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = F)+\n  labs(x = 'Dias', y = 'Estande de plantas')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nAjuste da regressão\nO coeficiente de determinação também foi baixo.\n\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473"
  },
  {
    "objectID": "Aula_9.html#gráfico-de-dispersão",
    "href": "Aula_9.html#gráfico-de-dispersão",
    "title": "Aula 9",
    "section": "Gráfico de dispersão",
    "text": "Gráfico de dispersão\n\nwm &lt;- WhiteMoldSoybean\n\nwm |&gt; \n  ggplot(aes(inc, yld)) +\n  geom_point() +\n  #facet_wrap(~ study) +\n  theme_minimal() +\n  geom_smooth(method = 'lm', se = T) +\n  labs(x = 'Incidência', y = ' Produtividade (kg/ha)')\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Aula_9.html#ajuste-do-modelo-1",
    "href": "Aula_9.html#ajuste-do-modelo-1",
    "title": "Aula 9",
    "section": "Ajuste do modelo",
    "text": "Ajuste do modelo\n\nmofo1 &lt;-  lm(yld ~ inc, data = wm)\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nfit_all &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = T))\nfit_all\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\n\nfit_all.interc &lt;- fit_all |&gt; \n  filter(term == \"(Intercept)\")\n\np1 &lt;- fit_all.interc |&gt; \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = 'white') +\n  theme_clean() +\n  labs(x = 'Intercept')\n\nfit_all.inc &lt;- fit_all |&gt; \n  filter(term == \".$inc\")\n\np2 &lt;- fit_all.inc |&gt; \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = 'white') +\n  theme_clean() +\n  labs(x = 'Incidence')\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\nmofo3 &lt;-  lmer(yld ~ inc + (inc|study), data = wm, REML = F)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nsummary(mofo3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAnova(mofo3) # para obter o valor p\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(&gt;Chisq)    \ninc 141.09  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(mofo3, method = 'Wald') # para o calcular o IC\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219"
  }
]