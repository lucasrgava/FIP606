{
  "hash": "42d3304d4abe7a8e6d1ba22c63a83cf4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aula 9\"\nformat: html\neditor: visual\n---\n\n\n# Pacotes\n\nCarregando pacotes necessários no código.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(lme4)\nlibrary(car)\nlibrary(DHARMa)\nlibrary(performance)\nlibrary(r4pde)\nlibrary(broom) # para usar a função 'do()'\nlibrary(patchwork)\nlibrary(emmeans)\nlibrary(multcomp)\n```\n:::\n\n\n# Importando banco de dados\n\nDados referentes a um ensaio realizado em DBC com parcelas subdividida, em esquema fatorial 6x2 com 4 repetições, totalizando 12 tratamentos. Os níveis do primeiro fator composto pelos híbridos: 30F53 HX; 30F53 YH; 30K64; 30S31H; 30S31YH e BG7049H. Os níveis do segundo fator composto por 2 métodos de inoculação: pin e silk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759')\n```\n:::\n\n\n## Gráfico\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados |> \n  ggplot(aes(method, index)) +\n  geom_jitter(width = 0.1, alpha = 0.5, color = 'black') + \n  facet_wrap(~hybrid) + \n  stat_summary(fun.data = 'mean_cl_boot', color = 'black') + \n  theme_clean()\n```\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Modelo para subdividida\n\n### Dados índice de doença\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados <-  dados |> \n  mutate(block = as.factor(block))\n\nmix2 <-  lmer(index ~ hybrid * method + block +(1|block/hybrid),data = dados )\n\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n### Premissas\n\nPremissa de homogeneidade de variâncias não atendida.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n\n\n:::\n:::\n\n\n### Transformação dos dados\n\nTransformação por raiz quadrada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix2 <- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = dados)\nmix2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: sqrt(index) ~ hybrid * method + block + (1 | block/hybrid)\n   Data: dados\nREML criterion at convergence: 72.5662\nRandom effects:\n Groups       Name        Std.Dev.\n hybrid:block (Intercept) 0.4644  \n block        (Intercept) 2.2518  \n Residual                 0.3742  \nNumber of obs: 48, groups:  hybrid:block, 24; block, 4\nFixed Effects:\n              (Intercept)             hybrid30F53 YH  \n                  4.65420                   -0.04446  \n              hybrid30K64               hybrid30S31H  \n                 -0.49224                    1.09866  \n            hybrid30S31YH              hybridBG7049H  \n                  0.63521                   -0.58990  \n               methodsilk                     block2  \n                 -0.05317                    0.06156  \n                   block3                     block4  \n                  0.56679                    0.73537  \nhybrid30F53 YH:methodsilk     hybrid30K64:methodsilk  \n                  0.20604                    0.16534  \n  hybrid30S31H:methodsilk   hybrid30S31YH:methodsilk  \n                 -0.91003                   -0.43778  \n hybridBG7049H:methodsilk  \n                  0.01751  \n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0783  3   0.994305   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nPremissas atendidas!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.970).\n```\n\n\n:::\n:::\n\n\n### Teste de comparações múltiplas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_milho <- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\nmedias_milho\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 11.6 5155     7.35     53.0\n 30F53 YH     24.5 11.5 5155     7.11     52.3\n 30K64        20.3 10.5 5155     4.93     46.1\n 30S31H       37.1 14.2 5155    14.52     70.2\n 30S31YH      31.7 13.1 5155    11.20     62.6\n BG7049H      19.4 10.3 5155     4.50     44.7\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 11.5 5155     7.07     52.2\n 30F53 YH     26.0 11.9 5155     7.95     54.6\n 30K64        21.3 10.8 5155     5.44     47.6\n 30S31H       26.3 12.0 5155     8.11     55.0\n 30S31YH      26.4 12.0 5155     8.16     55.1\n BG7049H      19.1 10.2 5155     4.35     44.3\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\nmedias_milho2 <- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\nmedias_milho2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 11.6 5155     7.35     53.0\n silk       24.4 11.5 5155     7.07     52.2\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 11.5 5155     7.11     52.3\n silk       26.0 11.9 5155     7.95     54.6\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.5 5155     4.93     46.1\n silk       21.3 10.8 5155     5.44     47.6\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.2 5155    14.52     70.2\n silk       26.3 12.0 5155     8.11     55.0\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.1 5155    11.20     62.6\n silk       26.4 12.0 5155     8.16     55.1\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.3 5155     4.50     44.7\n silk       19.1 10.2 5155     4.35     44.3\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_milho2, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 11.5 5155     7.07     52.2  a    \n pin        25.0 11.6 5155     7.35     53.0  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 11.5 5155     7.11     52.3  a    \n silk       26.0 11.9 5155     7.95     54.6  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.5 5155     4.93     46.1  a    \n silk       21.3 10.8 5155     5.44     47.6  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.0 5155     8.11     55.0  a    \n pin        37.1 14.2 5155    14.52     70.2   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.0 5155     8.16     55.1  a    \n pin        31.7 13.1 5155    11.20     62.6  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.2 5155     4.35     44.3  a    \n pin        19.4 10.3 5155     4.50     44.7  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## Dados de produtividade\n\n### Modelo e ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix3 <- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), data = dados)\n\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n### Premissas\n\nPremissas OK!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n\n\n:::\n:::\n\n\n### Teste de comparações múltiplas\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(emmeans(mix3, ~ hybrid | method,\n                    type = \"response\"), Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  a    \n 30S31H       8081 743 26.1     6626     9681  ab   \n 30F53 YH     9314 798 26.1     7746    11027  abc  \n 30F53 HX    11130 872 26.1     9410    12995   bc  \n 30K64       11666 893 26.1     9903    13574    c  \n BG7049H     11914 903 26.1    10131    13841    c  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  a    \n 30F53 YH     9079 788 26.1     7532    10770  a    \n 30S31H       9135 790 26.1     7583    10832  a    \n 30F53 HX     9932 824 26.1     8311    11698  ab   \n 30K64       10331 840 26.1     8676    12131  ab   \n BG7049H     12822 936 26.1    10970    14818   b   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n# Dados\n\nBanco de dados referente a 3 experimentos onde se avaliaram o estande de plantas ao longo do tempo. Os ensaios foram conduzidos em DBC com 4 repetições.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555')\n```\n:::\n\n\n# Gráfico\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados |> \n  ggplot(aes(trat, nplants)) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(method = 'lm', se = F) +\n  stat_summary(fun.data = 'mean_cl_boot', color = 'black') +\n  facet_wrap(~ exp) +\n  labs(x = 'Dias', y = 'Estande de plantas')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Dados do experimento 1\n\n### Gráfico\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp1 <-  dados |> \n  filter(exp == 1)\n\nexp1 |> \n  ggplot(aes(x = trat, y = nplants)) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = F)+\n  labs(x = 'Dias', y = 'Estande de plantas')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### Ajuste da regressão\n\nA regressão explica pouco a variação dos dados, visto que o coeficiente de determinação foi muito baixo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~ trat, \n          data = exp1)\n\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n:::\n\n\n## Dados do experimento 2\n\n### Gráfico\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <-  dados |> \n  filter(exp == 2)\n\nexp2 |> \n  ggplot(aes(x = trat, y = nplants)) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = F)+\n  labs(x = 'Dias', y = 'Estande de plantas')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Ajuste da regressão\n\nO coeficiente de determinação também foi baixo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~ trat, \n          data = exp2)\n\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n\n# Dados do experimento 3\n\n### Gráfico\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <-  dados |> \n  filter(exp == 3)\n\nexp3 |> \n  ggplot(aes(x = trat, y = nplants)) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n### Ajuste do modelo\n\nO coeficiente de determinação nesse caso foi um pouco maior. No entanto, não é considerado alto, visto que foi de 0,6.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm3 <- lm(nplants ~ trat, \n          data = exp3)\n\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n:::\n\n\n### GLMs\n\nAjustando dois modelos lineares generalizados e testando o ajuste em função do tipo de distribuição dos dados informados na função `glm()`. Para selecionar o melhor modelo, além de considerar o valor do coeficiente de determinação, levou-se em conta o do critério de Akaike. A função `AIC()` do pacote **stats**, calcula esse valor. A interpretação é que quanto menor o valor de AIC, melhor. Abaixo, foi ajustado dois modelos aos dados do experimento 2. Os modelos **glm2** e **glm2b** tiveram valores de AIC de 194,95 e 210,23, respectivamente. Logo, o primeiro modelo foi o que melhor se ajustou aos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~ trat, family = 'gaussian', data = exp2)\n\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2) # quanto menor, melhor\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n\n```{.r .cell-code}\nglm2b <-  glm(nplants ~ trat, family = 'poisson', data = exp2)\n\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n:::\n\n\n# Dados: Mofo branco da soja\n\n## Gráfico de dispersão\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm <- WhiteMoldSoybean\n\nwm |> \n  ggplot(aes(inc, yld)) +\n  geom_point() +\n  #facet_wrap(~ study) +\n  theme_minimal() +\n  geom_smooth(method = 'lm', se = T) +\n  labs(x = 'Incidência', y = ' Produtividade (kg/ha)')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Ajuste do modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <-  lm(yld ~ inc, data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_all <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~ .$inc), conf.int = T))\nfit_all\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_all.interc <- fit_all |> \n  filter(term == \"(Intercept)\")\n\np1 <- fit_all.interc |> \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = 'white') +\n  theme_clean() +\n  labs(x = 'Intercept')\n\nfit_all.inc <- fit_all |> \n  filter(term == \".$inc\")\n\np2 <- fit_all.inc |> \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = 'white') +\n  theme_clean() +\n  labs(x = 'Incidence')\n\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Aula_9_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo3 <-  lmer(yld ~ inc + (inc|study), data = wm, REML = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(mofo3) # para obter o valor p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method = 'Wald') # para o calcular o IC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Aula_9_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}